{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV: an algorithm for selecting the best parameters for a model; search over specified parameter values for an estimator in order to find the best combination of parameters for the estimator\n",
    "\n",
    "When to use?\n",
    "1) honestly most of the time if you are going to be dealing with a bunch of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = GridSearchCV(estimator, \n",
    "      param_grid, \n",
    "      scoring=None, \n",
    "      n_jobs=None, \n",
    "      refit=True, \n",
    "      cv=None, \n",
    "      verbose=0, \n",
    "      pre_dispatch='2*n_jobs', \n",
    "      error_score=nan, \n",
    "      return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##METHODS\n",
    "params.decision_function(X) #call on the estimator with the best found parameters\n",
    "params.fit() \n",
    "params.get_params([deep]) #get the parameters for this estimator\n",
    "params.inverse_transform(Xt) #call on the estimator with the best found params\n",
    "params.predict(X)\n",
    "params.predict_log_proba(X)\n",
    "params.predict_proba(X)\n",
    "params.score(X[,y]) #return the score on the given data, if the estimator has been refit\n",
    "params.score_samples(X) #call on the estimator with the best found parameters\n",
    "params.set_params()\n",
    "params.transform(X) #call on the estimator with the best found parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ATTRIBUTES\n",
    "params.cv_results_ \n",
    "params.best_estimator_ \n",
    "params.best_score_ \n",
    "params.best_params_ \n",
    "params.best_index_\n",
    "params.scorer_ \n",
    "params.n_splits_ \n",
    "params.refit_time_\n",
    "params.multimetric_ \n",
    "params.classes_ \n",
    "params.n_features_in_\n",
    "params.feature_names_in_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS\n",
    "\n",
    "    estimator= the estimator you are searching for; must have either a score function or 'scoring' must be passed \n",
    "\n",
    "    param_grid= dictionary with parameter names as keys and lists of parameter settings to try as values \n",
    "\n",
    "    scoring= strategy to evaluate the performance of the cross-validated model on the test set \n",
    "\n",
    "    n_jobs= parallel jobs running\n",
    "      --1 means use all available processors\n",
    "\n",
    "    refit= refit an estimator using the best found parameters on the whole dataset\n",
    "\n",
    "    cv= cross-validation splitting strategy\n",
    "      -None : default to use t5-fold cross validation\n",
    "      -int: to specify the number of folds in a (Stratified)KFold\n",
    "      -CV splitter\n",
    "      -iter : yielding (train, test) splits as arrays of indices \n",
    "\n",
    "    verbose= how many describing messages the function will output \n",
    "      -1 : the computation time for each fold and parameter candidate is displayed\n",
    "      -2 : the score is also displayed\n",
    "      -3 : the fold and candidate parameter indexes are also displayed together with the starting time of the computation\n",
    "\n",
    "    pre_dispatch= number of jobs that get dispatched during parallel execution; reducing can help avoid excessive RAM usage if that is an issue\n",
    "      -None\n",
    "      -int : exact number of jobs that are spawned\n",
    "      -str : an expression of n_jobs; ex. '2*n_jobs'\n",
    "\n",
    "    error_score=value to assign to the score if an error occurs during fitting\n",
    "      -'raise' : the error is raised\n",
    "      -int : FitFailedWarning is raised\n",
    "      -np.nan : default, raises no error\n",
    "\n",
    "    return_train_score= whether or not the training scores will be given in the results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTRIBUTES\n",
    "      cv_results_ : a dictionary with keys as column headers and values as columns\n",
    "\n",
    "      best_estimator_ : estimator dubbed the best by the grid search (not available if refit=False)\n",
    "\n",
    "      best_score_ : the mean cross-validated score of the best estimator(not available if refit is a function)\n",
    "\n",
    "      best_params_ : parameter setting that gave the best results on the hold out data\n",
    "\n",
    "      best_index_ : index that corresponds to the best candidate parameter setting in the cv_results_\n",
    "\n",
    "      scorer_ : function used on the held out data to choose the best parameters\n",
    "\n",
    "      n_splits_ : number of cross-validation splits (folds)\n",
    "\n",
    "      refit_time_ : seconds used for refitting the best model (only if refit=True)\n",
    "\n",
    "      multimetric_ : whether or not the scorers compute several metrics\n",
    "\n",
    "      classes_ : class labels\n",
    "\n",
    "      n_features_in_ : number of features seen during fit\n",
    "      \n",
    "      feature_names_in_ : names of the above features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
