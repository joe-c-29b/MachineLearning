{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosted Regression Tree algorithm: classifier that takes the input from an ensemble and votes/averages for a final collective decision\n",
    "When to use?\n",
    "1) used for boosting performance of several estimators together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clfr = VotingClassifier(estimators=[], \n",
    "                        voting='hard', \n",
    "                        weights=None, \n",
    "                        n_jobs=None, \n",
    "                        flatten_transform=True, \n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "reg = VotingRegressor(estimators=[], \n",
    "                        weights=None, \n",
    "                        n_jobs=None,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##METHODS\n",
    "reg.fit(X, y[, sample_weight]) #fit the estimators\n",
    "reg.fit_transform(X[,y]) #output class labels or probabilities for each estimator\n",
    "reg.get_features_names_out([input_features]) #output feature names for transformation\n",
    "reg.get_params([deep]) #parameters of an estimator from the ensemble\n",
    "reg.predict(X) #predict class labels for X\n",
    "reg.score(X, y[, sample_weight]) #return mean accuracy on the given test data and labels\n",
    "reg.set_output(*[, transform]) #set output container\n",
    "reg.set_params(**params) #set the parameters of an estimator from the ensemble\n",
    "reg.transform(X) #return class labels or probabilities for X for each estimator\n",
    "\n",
    "clfr.fit(X, y[, sample_weight]) #fit the estimators\n",
    "clfr.fit_transform(X[,y]) #output class labels or probabilities for each estimator\n",
    "clfr.get_features_names_out([input_features]) #output feature names for transformation\n",
    "clfr.get_params([deep]) #parameters of an estimator from the ensemble\n",
    "clfr.predict(X) #predict class labels for X\n",
    "clfr.predict_proba(X) #predict probabilities for each possible outcome (classifier only) \n",
    "clfr.score(X, y[, sample_weight]) #return mean accuracy on the given test data and labels\n",
    "clfr.set_output(*[, transform]) #set output container\n",
    "clfr.set_params(**params) #set the parameters of an estimator from the ensemble\n",
    "clfr.transform(X) #return class labels or probabilities for X for each estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ATTRIBUTES\n",
    "clfr.estimators_  #list of the sub-estimators contained for voting\n",
    "clfr.named_estimators_ #access any of the interior estimators by name\n",
    "clfr.le_ #transformer used to encode the labels during fit and decode during prediction #(classifier only)\n",
    "clfr.classes_ #the classes labels #(classifier only)\n",
    "clfr.n_features_in_ #number of features seen during fit\n",
    "clfr.feature_names_in_ #names of features seen during fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS\n",
    "estimators= the list of interior estimators that will be voting;invoking the fit method on the voting classifier will fit clones of those original estimators that will be stored in the class attribute\n",
    "weights= pre-weighting the predicted class before voting\n",
    "n_jobs= number of parallel jobs\n",
    "    - -1 means using all available processors\n",
    "verbose= output of messages after execution\n",
    "    -True : output time elapsed while fitting\n",
    "    -False : no output message following execution\n",
    "\n",
    "\n",
    "(classifier only) voting= what type of voting will be used\n",
    "    -'hard' each interior estimator decides a class that it will vote on; every estimator gets one vote\n",
    "    -'soft' each interior estimator predicts a probability  and the voting is done based on weight\n",
    "(classifier only) flatten_transform= affects the shape of transform output (only when voting='soft')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTRIBUTES\n",
    "estimators_ : list of the sub-estimators contained for voting\n",
    "named_estimators_ : access any of the interior estimators by name\n",
    "(classifier only)le_ : transformer used to encode the labels during fit and decode during prediction\n",
    "(classifier only)classes_ : the classes labels\n",
    "n_features_in_ : number of features seen during fit\n",
    "feature_names_in_ : names of features seen during fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
